{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# README\n",
    "\n",
    "### Purpose of this notebook\n",
    "- Create the application dataframe.\n",
    "- Preprocess application.\n",
    "\n",
    "### Steps\n",
    "\n",
    "#### Create the application dataframe\n",
    "1. Read the application text\n",
    "2. Find the width and height of each application page\n",
    "\n",
    "#### Preprocess application\n",
    "1. Split application into multi-document (currently year 111 only)\n",
    "2. Extract self-statement from application\n",
    "3. Preprocess self-statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import string\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "from importlib import reload\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress: \")\n",
    "\n",
    "# Chinese character set\n",
    "from zhon import hanzi\n",
    "import opencc\n",
    "\n",
    "# Utility variable\n",
    "import sys\n",
    "sys.path.insert(0, '../..')\n",
    "\n",
    "# var\n",
    "import var.var as V\n",
    "import var.path as P\n",
    "\n",
    "# utils\n",
    "import utils.data as D\n",
    "import utils.io as IO\n",
    "import utils.get_path as GP\n",
    "import utils.preprocess as PP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = opencc.OpenCC('s2tw')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create application dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P.YEAR_DIRS, P.FP_FULL_APPLICATIONS_TXT_OCR_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_applications_old = D.read_df_applications()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_applications_data = []\n",
    "\n",
    "for year, year_txt_ocr_dir in zip(P.YEAR_DIRS, P.FP_FULL_APPLICATIONS_TXT_OCR_DIR):\n",
    "    if year != '112':\n",
    "        continue\n",
    "    \n",
    "    for app in os.listdir(year_txt_ocr_dir):\n",
    "        if \".json\" not in app:\n",
    "            continue\n",
    "            \n",
    "        _id = app.split('.')[0]\n",
    "        \n",
    "        fp = os.path.join(year_txt_ocr_dir, app)\n",
    "            \n",
    "        with open(fp, 'r') as f:\n",
    "            app_texts = json.load(f)\n",
    "    \n",
    "        _year = int(year)\n",
    "        _id = int(_id)\n",
    "        \n",
    "        if len(df_applications_old.query(\"`year` == @_year and `id` == @_id\").index) == 0:\n",
    "            row_data = {\n",
    "                'year': int(year),\n",
    "                'id': int(_id),\n",
    "                'application_pages': app_texts,\n",
    "                'num_pages': len(app_texts)\n",
    "            }\n",
    "\n",
    "            df_applications_data.append(row_data)\n",
    "\n",
    "df_applications = pd.DataFrame(df_applications_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_applications.sort_values(['year', 'id'], inplace=True)\n",
    "df_applications.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_applications.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_applications.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the width and height of each application page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P.FP_FULL_APPLICATIONS_TXT_OCR_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_items(dictionary, level):\n",
    "    for key, value in dictionary.items():\n",
    "        if type(value) is dict:\n",
    "            yield key, level\n",
    "            yield from recursive_items(value, level+1)\n",
    "        else:\n",
    "            yield key, level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_width_height_data = []\n",
    "\n",
    "for _, row in tqdm(df_applications.iterrows(), total=df_applications.shape[0]):\n",
    "    _year = str(row['year'])\n",
    "    _id = str(row['id'])\n",
    "\n",
    "#     print(_year, _id)\n",
    "    _dir = GP.get_application_page_raw_ocr_dir(_year, _id)\n",
    "\n",
    "    files = os.listdir(_dir)\n",
    "    files = [f for f in files if 'output' in f]\n",
    "    files = sorted(files, key=lambda f: int(f.split('-')[1]))\n",
    "#     print(files)\n",
    "\n",
    "    page_width_height = []\n",
    "        \n",
    "    for file in files:\n",
    "        rfp = os.path.join(_dir, file)\n",
    "\n",
    "        with open(rfp, 'r') as rf:\n",
    "            res = json.load(rf)\n",
    "\n",
    "#             for key, level in recursive_items(res, 0):\n",
    "#                 print('{}{}'.format('--'*level, key))\n",
    "                \n",
    "            for page in res['responses']:\n",
    "                try:\n",
    "                    page_info = page['fullTextAnnotation']['pages'][0]\n",
    "                    page_width = page_info['width']\n",
    "                    page_height = page_info['height']\n",
    "                except:\n",
    "                    page_width = 0\n",
    "                    page_height = 0\n",
    "        \n",
    "                page_width_height.append((page_width, page_height))          \n",
    "    \n",
    "    page_width_height_data.append(page_width_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_applications['page_width_height'] = page_width_height_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_applications.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split applications into multi-document including:\n",
    "- data sheet\n",
    "- qualification, transcript, eligibility\n",
    "- self-statement\n",
    "- portfolio\n",
    "- others\n",
    "- recommendation letters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find obvious boundaries from application after year 111 (inclusive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cover_keyword = \"NATIONAL TSING HUA UNIVERSITY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V.COVER_PAGE_TITLE_LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_application_year_111(row):\n",
    "    year = row['year']\n",
    "    app = row['application_pages']\n",
    "    \n",
    "    if year < 111:\n",
    "        return []\n",
    "    \n",
    "    ## year 111\n",
    "    cover_pn = [pn for pn, page in enumerate(app) if cover_keyword in page]\n",
    "    ## filter false positive\n",
    "    cover_pn = [pn for pn in cover_pn if \n",
    "                any(1 for keyword in V.COVER_PAGE_TITLE_LIST if keyword in app[pn])]\n",
    "    ## filter false positive\n",
    "    cover_pn = [pn for pn in cover_pn if len(app[pn]) < 100]\n",
    "    ## filter duplicate\n",
    "    for keyword in V.COVER_PAGE_TITLE_LIST:\n",
    "        pns = [pn for pn in cover_pn if keyword in app[pn]]\n",
    "        \n",
    "        ## remove pn except for the first occurence\n",
    "        for remove_pn in pns[1:]:\n",
    "            cover_pn.remove(remove_pn)\n",
    "    \n",
    "    return cover_pn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_applications['boundaries'] = df_applications.apply(split_application_year_111, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_applications['boundaries'].apply(len).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cn = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in df_applications.iterrows():\n",
    "    boundaries = row['boundaries']\n",
    "    app = row['application_pages']\n",
    "    \n",
    "    cover_pages = '\\n'.join([app[pn] for pn in boundaries])\n",
    "    titles = [keyword for keyword in V.COVER_PAGE_TITLE_LIST if keyword in cover_pages]\n",
    "    titles = ' '.join(titles)\n",
    "    cn[titles] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find page span for each section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_application_section_span_year_111(row):\n",
    "    year = row['year']\n",
    "    app = row['application_pages']\n",
    "    boundaries = row['boundaries']\n",
    "    \n",
    "    if year < 111:\n",
    "        return {}\n",
    "\n",
    "    section_span = {}\n",
    "    \n",
    "    cover_pages = '\\n'.join([app[pn] for pn in boundaries])\n",
    "    titles = [keyword for keyword in V.COVER_PAGE_TITLE_LIST if keyword in cover_pages]\n",
    "    assert len(boundaries) == len(titles)\n",
    "    \n",
    "    for i, title in enumerate(titles):\n",
    "        try:\n",
    "            section_span[title] = (boundaries[i], boundaries[i+1])\n",
    "        except:\n",
    "            section_span[title] = (boundaries[i], len(app))\n",
    "        \n",
    "    return section_span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_applications['section_span'] = df_applications.apply(find_application_section_span_year_111, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_applications.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_applications.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in df_applications.tail().iterrows():\n",
    "    boundaries = row['boundaries']\n",
    "    section_span = row['section_span']\n",
    "    \n",
    "    print(boundaries)\n",
    "    print(section_span)\n",
    "    IO.print_dividing_line()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D.write_df_applications(df_applications, file='csv')\n",
    "D.write_df_applications(df_applications, file='pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research_venv",
   "language": "python",
   "name": "research_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
