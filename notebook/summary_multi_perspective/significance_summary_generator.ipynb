{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6809198",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "from itertools import chain\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "from importlib import reload\n",
    "\n",
    "# Utility variable\n",
    "import sys, getopt\n",
    "sys.path.insert(0, '../..')\n",
    "\n",
    "# var\n",
    "import var.var as V\n",
    "import var.path as P\n",
    "\n",
    "# utils\n",
    "import utils.data as D\n",
    "import utils.io as IO\n",
    "import utils.preprocess as PP\n",
    "import utils.torch as Tor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a687e408",
   "metadata": {},
   "source": [
    "## Process Command Line Arguments\n",
    "- command: `python3 1_comment_articut_word_graph.py <option>`\n",
    "- options:\n",
    "    - `-d <model save dir name>`\n",
    "    - `-e <epoch>`\n",
    "    - `-m <mmr lambda>` \n",
    "    - `-b <batch size>`\n",
    "    - `-t`: inference on year 112"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de5f90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## parse arguments\n",
    "opts, args = getopt.getopt(sys.argv[1:], \"d:e:m:b:f:s:a:t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab40c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_SAVE_DIR_NAME = \"significance_pHAN_cmt_cos_dist_w_cmt_aug_train_2022-12-09_mixed_1\"\n",
    "EPOCH = 20\n",
    "MMR_LAMBDA = 0.7\n",
    "BATCH_SIZE = 12\n",
    "VAL_OR_TEST = 'val'\n",
    "MAX_SENT = 8\n",
    "COMBINED_ATT_MIN_THRESHOLD = 0.03\n",
    "ATT_THRESHOLD_DECAY = 0.005\n",
    "RL_WEIGHT_BOOST = 1.05\n",
    "\n",
    "GPU_NUM = 0\n",
    "\n",
    "for opt, arg in opts:\n",
    "    if opt == '-d':\n",
    "        MODEL_SAVE_DIR_NAME = arg\n",
    "    elif opt == '-e':\n",
    "        EPOCH = int(arg)\n",
    "    elif opt == '-m':\n",
    "        MMR_LAMBDA = float(arg)\n",
    "    elif opt == '-b':\n",
    "        BATCH_SIZE = int(arg)\n",
    "    elif opt == '-s':\n",
    "        MAX_SENT = int(arg)\n",
    "    elif opt == '-a':\n",
    "        COMBINED_ATT_MIN_THRESHOLD = float(arg)\n",
    "    elif opt == '-t':\n",
    "        VAL_OR_TEST = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4485273c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'train' in MODEL_SAVE_DIR_NAME:\n",
    "    perspective_title = V.TRAIN_PERSPECTIVE_TITLE\n",
    "    TRAIN_OR_ALL = 'train'\n",
    "elif 'all' in MODEL_SAVE_DIR_NAME:\n",
    "    perspective_title = V.ALL_PERSPECTIVE_TITLE\n",
    "    TRAIN_OR_ALL = 'all'\n",
    "    \n",
    "if 'wo' in MODEL_SAVE_DIR_NAME:\n",
    "    COMMENT_AUGMENTATION = False\n",
    "else:\n",
    "    COMMENT_AUGMENTATION = True\n",
    "    \n",
    "## hyper parameters to load\n",
    "USE_SBERT_EMBED = None\n",
    "USE_BERT_EMBED = None\n",
    "NUM_PERSPECTIVE = 0\n",
    "# TRAIN_OR_ALL = ''\n",
    "TOP_K = 0\n",
    "BERT_MODEL_NAME = ''\n",
    "BERT_TOKENIZER_NAME = ''\n",
    "BERTOPIC_MODEL_NAME = ''\n",
    "\n",
    "## pHAN params\n",
    "BERT_DIM = 0\n",
    "SENT_DIM = 0\n",
    "CXT_DIM = 0\n",
    "PRJ_DIM = 0\n",
    "COMPRESSION = None\n",
    "PROJECTION = None\n",
    "ATTENTION_EMPTY_MASK = None\n",
    "FREEZE_BERT = None\n",
    "SENT_TEMPERATURE = 0\n",
    "PERS_TEMPERATURE = 0\n",
    "DROPOUT_RATE = 0\n",
    "LEAKY_RELU_NEG_SLOPE = 0\n",
    "ENC_BZ = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e78523",
   "metadata": {},
   "source": [
    "## Load hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0921e496",
   "metadata": {},
   "outputs": [],
   "source": [
    "if COMMENT_AUGMENTATION:\n",
    "    MODEL_SAVE_DIR_PATH = os.path.join(P.FP_SIGNIFICANCE_PHAN_DIR, TRAIN_OR_ALL, 'w', MODEL_SAVE_DIR_NAME)\n",
    "else:\n",
    "    MODEL_SAVE_DIR_PATH = os.path.join(P.FP_SIGNIFICANCE_PHAN_DIR, TRAIN_OR_ALL, 'wo', MODEL_SAVE_DIR_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173767fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417752a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_hyperparams(t):\n",
    "    ## find model name\n",
    "    model_name = \"epoch_{:04d}.pt\".format(t)\n",
    "    fn = os.path.join(MODEL_SAVE_DIR_PATH, model_name)\n",
    "    checkpoint = torch.load(fn)\n",
    "    \n",
    "    global USE_SBERT_EMBED\n",
    "    global USE_BERT_EMBED\n",
    "    global NUM_PERSPECTIVE\n",
    "    global TRAIN_OR_ALL\n",
    "    global TOP_K\n",
    "    global BERT_MODEL_NAME\n",
    "    global BERT_TOKENIZER_NAME\n",
    "    global BERTOPIC_MODEL_NAME\n",
    "    global COMMENT_AUGMENTATION\n",
    "    global perspective_mean_embed\n",
    "    global BERT_DIM\n",
    "    global SENT_DIM\n",
    "    global CXT_DIM\n",
    "    global PRJ_DIM\n",
    "    global COMPRESSION\n",
    "    global PROJECTION\n",
    "    global ATTENTION_EMPTY_MASK\n",
    "    global FREEZE_BERT\n",
    "    global SENT_TEMPERATURE\n",
    "    global PERS_TEMPERATURE\n",
    "    global DROPOUT_RATE\n",
    "    global LEAKY_RELU_NEG_SLOPE\n",
    "    global RANDOM_STATE\n",
    "    global ENC_BZ\n",
    "    \n",
    "    USE_SBERT_EMBED = checkpoint['use_sbert_embed']\n",
    "    USE_BERT_EMBED = checkpoint['use_bert_embed']\n",
    "    NUM_PERSPECTIVE = checkpoint['num_perspective']\n",
    "    TRAIN_OR_ALL = checkpoint['train_or_all']\n",
    "    TOP_K = checkpoint['top_k']\n",
    "    BERT_MODEL_NAME = checkpoint['bert_model']\n",
    "    BERT_TOKENIZER_NAME = checkpoint['bert_tokenizer']\n",
    "    BERTOPIC_MODEL_NAME = checkpoint['bert_topic_model']\n",
    "    COMMENT_AUGMENTATION = checkpoint['comment_augmentation']\n",
    "    perspective_mean_embed = checkpoint['perspective_mean_embed']\n",
    "    BERT_DIM = checkpoint['bert_dim']\n",
    "    SENT_DIM = checkpoint['sent_dim']\n",
    "    CXT_DIM = checkpoint['cxt_dim']\n",
    "    PRJ_DIM = checkpoint['prj_dim']\n",
    "    try:\n",
    "        COMPRESSION = checkpoint['compression']\n",
    "    except:\n",
    "        COMPRESSION = True\n",
    "    try:\n",
    "        PROJECTION = checkpoint['projection']\n",
    "    except:\n",
    "        PROJECTION = True\n",
    "    try:\n",
    "        ATTENTION_EMPTY_MASK = checkpoint['attention_empty_mask']\n",
    "    except:\n",
    "        ATTENTION_EMPTY_MASK = False\n",
    "    FREEZE_BERT = checkpoint['freeze_bert']\n",
    "    SENT_TEMPERATURE = checkpoint['sent_temperature']\n",
    "    PERS_TEMPERATURE = checkpoint['pers_temperature']\n",
    "    DROPOUT_RATE = checkpoint['dropout_rate']\n",
    "    LEAKY_RELU_NEG_SLOPE = checkpoint['leaky_relu_negative_slope']\n",
    "    ENC_BZ = checkpoint['encode_batch_size']\n",
    "    RANDOM_STATE = checkpoint['random_state']\n",
    "    \n",
    "    np.random.seed(RANDOM_STATE)\n",
    "    \n",
    "    assert (USE_SBERT_EMBED or USE_BERT_EMBED) == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5364685",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_hyperparams(EPOCH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c171ff0",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a54f48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a85db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(GPU_NUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85d95a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytz\n",
    "timezone = pytz.timezone('Asia/Taipei')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69138022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable hugging face tokenizer parallelism\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b544f2",
   "metadata": {},
   "source": [
    "### setup logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7301cd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "if COMMENT_AUGMENTATION:\n",
    "    summary_docx_dir = os.path.join(\n",
    "        P.FP_SIGNIFICANCE_SUMMARY_DIR, TRAIN_OR_ALL, 'w', MODEL_SAVE_DIR_NAME, \"epoch_{}_max_sent_{}\".format(EPOCH, MAX_SENT)\n",
    "    )\n",
    "else:\n",
    "    summary_docx_dir = os.path.join(\n",
    "        P.FP_SIGNIFICANCE_SUMMARY_DIR, TRAIN_OR_ALL, 'wo', MODEL_SAVE_DIR_NAME, \"epoch_{}_max_sent_{}\".format(EPOCH, MAX_SENT)\n",
    "    )\n",
    "\n",
    "summary_debug_dir = os.path.join(\n",
    "    summary_docx_dir, \"debug\"\n",
    ")\n",
    "    \n",
    "if not os.path.exists(summary_docx_dir):\n",
    "    os.makedirs(summary_docx_dir)\n",
    "    \n",
    "if not os.path.exists(summary_debug_dir):\n",
    "    os.makedirs(summary_debug_dir)\n",
    "    \n",
    "pseudo_summary_dir = os.path.join(P.FP_SIGNIFICANCE_PSEUDO_SUMMARY_DIR, 'custom_bertopic', TRAIN_OR_ALL)\n",
    "all_data_dir = os.path.join(pseudo_summary_dir, 'all_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8993bf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "for handler in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f32f407",
   "metadata": {},
   "outputs": [],
   "source": [
    "import var.path as P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968012fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if COMMENT_AUGMENTATION:\n",
    "    log_file = os.path.join(P.FP_SIGNIFICANCE_SUMMARY_DIR, TRAIN_OR_ALL, 'w', MODEL_SAVE_DIR_NAME, 'summary_gen_log.log')\n",
    "else:\n",
    "    log_file = os.path.join(P.FP_SIGNIFICANCE_SUMMARY_DIR, TRAIN_OR_ALL, 'wo', MODEL_SAVE_DIR_NAME, 'summary_gen_log.log')\n",
    "    \n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "# create file handler which logs even debug messages\n",
    "fh = logging.FileHandler(log_file)\n",
    "fh.setLevel(logging.INFO)\n",
    "# create console handler with a higher log level\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.INFO)\n",
    "# add the handlers to logger\n",
    "logger.addHandler(ch)\n",
    "logger.addHandler(fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec07957",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622e800c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def defaultdict_init_defaultdict_init_by_int():\n",
    "    return defaultdict(int)\n",
    "\n",
    "def defaultdict_init_defaultdict_init_by_float():\n",
    "    return defaultdict(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b377b4a8",
   "metadata": {},
   "source": [
    "## Read raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b918ba6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_comments = D.read_df_comments()\n",
    "df_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb9ab23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_applicants = D.read_df_applicants()\n",
    "df_applicants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc94992b",
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_data = []\n",
    "if VAL_OR_TEST == 'val':\n",
    "    year_dir = V.YEAR_DIRS[:-1]\n",
    "elif VAL_OR_TEST == 'test':\n",
    "    year_dir = V.YEAR_DIRS[-1:]\n",
    "\n",
    "for year in year_dir:\n",
    "    _dir = os.path.join(P.FP_SIGNIFICANCE_PSEUDO_SUMMARY_DIR, 'custom_bertopic', TRAIN_OR_ALL, year)\n",
    "    \n",
    "    for file in os.listdir(_dir):\n",
    "        if file == '.ipynb_checkpoints':\n",
    "            continue\n",
    "\n",
    "        fn = os.path.join(_dir, file)\n",
    "\n",
    "        with open(fn, \"rb\") as f:\n",
    "            data = pickle.load(f)\n",
    "            individual_data.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6350ca58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(individual_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee76d305",
   "metadata": {},
   "outputs": [],
   "source": [
    "def defaultdict_init_defaultdict_init_by_int():\n",
    "    return defaultdict(int)\n",
    "\n",
    "def defaultdict_init_defaultdict_init_by_float():\n",
    "    return defaultdict(float)\n",
    "\n",
    "def defaultdict_init_defaultdict_init_by_str():\n",
    "    return defaultdict(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7169de59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recommendation_letters = D.read_df_recommendation_letters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6278875d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rl_info_dict = defaultdict(defaultdict_init_defaultdict_init_by_str)\n",
    "\n",
    "for _, row in df_recommendation_letters.iterrows():\n",
    "    _year = int(row['year'])\n",
    "    _id = int(row['id'])\n",
    "\n",
    "    rl_sent = row['all_paragraph_sent']\n",
    "    info = \"ï¼Œ\".join(row['info'])\n",
    "    \n",
    "    if info == \"\":\n",
    "        continue\n",
    "        \n",
    "    sent_info_dict = defaultdict_init_defaultdict_init_by_str()\n",
    "    \n",
    "    for sent in rl_sent:\n",
    "        sent_info_dict[sent] = info\n",
    "        \n",
    "    rl_info_dict[(_year, _id)] = rl_info_dict[(_year, _id)] | sent_info_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065aded7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_candidate_sents_info_buffer = {}\n",
    "# all_chunk_debug_info_buffer = {}\n",
    "\n",
    "# for file in tqdm(os.listdir(all_data_dir)):\n",
    "#     fn = os.path.join(all_data_dir, file)\n",
    "    \n",
    "#     if os.path.isdir(fn):\n",
    "#         continue\n",
    "        \n",
    "#     with open(fn, \"rb\") as f:\n",
    "#         group_data = pickle.load(f)\n",
    "        \n",
    "#     candidate_sents_info_buffer = group_data[\"candidate_sents_info_buffer\"]\n",
    "#     chunk_debug_info_buffer = group_data[\"chunk_debug_info_buffer\"]\n",
    "    \n",
    "#     all_candidate_sents_info_buffer |= candidate_sents_info_buffer\n",
    "#     all_chunk_debug_info_buffer |= chunk_debug_info_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6424e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(all_candidate_sents_info_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd36a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(all_chunk_debug_info_buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83180c1",
   "metadata": {},
   "source": [
    "## Prepare training data and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af0188a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_info_data = []\n",
    "test_pseudo_summary_data = []\n",
    "test_comment_data = []\n",
    "test_grade_data = []\n",
    "\n",
    "# pseudo_summary_to_info_dict = {}\n",
    "\n",
    "if VAL_OR_TEST == 'val':\n",
    "    for data in tqdm(individual_data):\n",
    "        _year = data['year']\n",
    "        _id = data['id']\n",
    "        _name = data['name']\n",
    "        pseudo_summary = data['pseudo_summary']\n",
    "\n",
    "        ## check train or test data\n",
    "        row = df_applicants.query('`year` == {} and `id` == {}'.format(_year, _id))\n",
    "        try:\n",
    "            train_or_test = row['train_or_test'].to_list()[0]\n",
    "        except:\n",
    "            train_or_test = 'train'\n",
    "\n",
    "        if train_or_test == 'train':\n",
    "            continue\n",
    "            \n",
    "        ## get corresponding comments\n",
    "        row = df_comments.query('`year` == {} and `id` == {}'.format(_year, _id))\n",
    "        comments = row['comment'].to_list()\n",
    "        grades = row['grade'].to_list()\n",
    "\n",
    "        ## append test data set\n",
    "        for comment, grade in zip(comments, grades):\n",
    "            ## remove empty comment\n",
    "            if PP.is_empty_sent(comment):\n",
    "                continue\n",
    "\n",
    "            test_info_data.append((_year, _id, _name))\n",
    "            test_comment_data.append(comment)\n",
    "            test_pseudo_summary_data.append(pseudo_summary)\n",
    "            test_grade_data.append(grade)\n",
    "                \n",
    "elif VAL_OR_TEST == 'test':\n",
    "    for data in tqdm(individual_data):\n",
    "        _year = data['year']\n",
    "        _id = data['id']\n",
    "        _name = data['name']\n",
    "        pseudo_summary = data['pseudo_summary']\n",
    "\n",
    "        ## append data to test data set\n",
    "        test_info_data.append((_year, _id, _name))\n",
    "        test_comment_data.append('') ## stuff empty comment\n",
    "        test_pseudo_summary_data.append(pseudo_summary)\n",
    "        test_grade_data.append('F') ## stuff empty comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36573367",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_info_data), len(test_pseudo_summary_data), len(test_comment_data), len(test_grade_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac30c6ba",
   "metadata": {},
   "source": [
    "### Apply one hot encoder to grade label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b821899c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdae9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "V.TRAIN_GRADE_LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78350059",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder()\n",
    "one_hot_vector = enc.fit_transform(V.TRAIN_GRADE_LABELS).toarray()\n",
    "one_hot_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdda63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ext_grade_data = np.array(test_grade_data).reshape(-1, 1)\n",
    "test_ext_grade_data = enc.transform(test_ext_grade_data).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75665df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ext_grade_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992f2edf",
   "metadata": {},
   "source": [
    "### Create dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4a6fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa02e859",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PseudoSummaryEvaluationDataset(Dataset):\n",
    "    def __init__(self, infos, pseudo_summaries, comments, grades):\n",
    "        ## list of sentences\n",
    "        self.infos = infos\n",
    "        self.pseudo_summaries = pseudo_summaries\n",
    "        self.comments = comments\n",
    "        self.grades = grades\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.grades)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        info = self.infos[idx]\n",
    "        pseudo_summary = self.pseudo_summaries[idx]\n",
    "        comment = self.comments[idx]\n",
    "        grade = self.grades[idx]\n",
    "        \n",
    "        return info, pseudo_summary, comment, grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6e1aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = PseudoSummaryEvaluationDataset(\n",
    "    test_info_data, test_pseudo_summary_data, test_comment_data, test_ext_grade_data\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, batch_size=BATCH_SIZE, collate_fn=lambda batch: batch,\n",
    "    num_workers=8, pin_memory=True, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810b9abc",
   "metadata": {},
   "source": [
    "# Load previous model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f8ebd2",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fa0365",
   "metadata": {},
   "source": [
    "### Load BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae69b04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_SBERT_EMBED:\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    \n",
    "    bert_tokenizer = None\n",
    "    bert_model = SentenceTransformer(BERT_MODEL_NAME).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bfd8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_BERT_EMBED:\n",
    "    from transformers import BertTokenizerFast, AutoModel\n",
    "\n",
    "    bert_tokenizer = BertTokenizerFast.from_pretrained(BERT_TOKENIZER_NAME)\n",
    "    bert_model = AutoModel.from_pretrained(BERT_MODEL_NAME).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c657371f",
   "metadata": {},
   "source": [
    "### Attention Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9d7a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b5795d",
   "metadata": {},
   "source": [
    "### Perspective HAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a0612f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.pHAN as PHAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c0193e",
   "metadata": {},
   "source": [
    "## Training loop & testing loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b287c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff08445",
   "metadata": {},
   "outputs": [],
   "source": [
    "## utils\n",
    "def get_data(batch):\n",
    "    batch_infos = [p[0] for p in batch]\n",
    "    batch_pseudo_summaries = [p[1] for p in batch]\n",
    "    batch_comments = [p[2] for p in batch]\n",
    "    batch_grades = np.array([p[3] for p in batch])\n",
    "    \n",
    "    return batch_infos, batch_pseudo_summaries, batch_comments, batch_grades\n",
    "\n",
    "def logit_to_label(logits, return_numpy=False):\n",
    "    ## convert logits to labels\n",
    "    labels_idx = torch.argmax(logits, 1).cpu().detach().numpy()\n",
    "    labels = [V.GRADE_INDEX_TO_LABEL[idx] for idx in labels_idx]\n",
    "    \n",
    "    if return_numpy:\n",
    "        return np.array(labels)\n",
    "    \n",
    "    return labels\n",
    "\n",
    "def decouple_loss_fn_dict(d):\n",
    "    cls_loss_fn = d[\"cls_loss_fn\"]\n",
    "    cos_dis_loss_fn = d[\"cos_dis_loss_fn\"]\n",
    "    con_loss_fn = d[\"con_loss_fn\"]\n",
    "    \n",
    "    return cls_loss_fn, cos_dis_loss_fn, con_loss_fn\n",
    "\n",
    "def decouple_loss_weight_dict(d):\n",
    "    cls_loss_weight = d[\"cls_loss_weight\"]\n",
    "    cos_dis_loss_weight = d[\"cos_dis_loss_weight\"]\n",
    "    con_loss_weight = d[\"con_loss_weight\"]\n",
    "\n",
    "    return cls_loss_weight, cos_dis_loss_weight, con_loss_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be05081",
   "metadata": {},
   "source": [
    "## Model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f62cbd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pHAN = PHAN.PerspectiveHierarchicalAttentionNetwork(\n",
    "    bert_model, bert_tokenizer, perspective_mean_embed, \n",
    "    NUM_PERSPECTIVE, TOP_K, BERT_DIM, SENT_DIM, CXT_DIM, PRJ_DIM, \n",
    "    sent_temperature=SENT_TEMPERATURE, pers_temperature=PERS_TEMPERATURE, \n",
    "    dropout_rate=DROPOUT_RATE, leaky_relu_negative_slope=LEAKY_RELU_NEG_SLOPE, \n",
    "    encode_batch_size=ENC_BZ, compression=COMPRESSION, projection=PROJECTION,\n",
    "    attention_empty_mask=ATTENTION_EMPTY_MASK, freeze_bert=FREEZE_BERT,\n",
    ").to(device)\n",
    "pHAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a2ec2e",
   "metadata": {},
   "source": [
    "### Number of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e53e096",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_params = torch.tensor(0)\n",
    "\n",
    "for parameter in pHAN.parameters():\n",
    "    if parameter.requires_grad:\n",
    "        num_params += torch.prod(torch.tensor(parameter.shape))\n",
    "\n",
    "num_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da2f928",
   "metadata": {},
   "source": [
    "## Test on test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b201510b",
   "metadata": {},
   "source": [
    "### Loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d9c961",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_metric_learning import losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914f674f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## classification loss\n",
    "weight = torch.tensor([3, 1.5, 1, 1]).to(device)\n",
    "# weight = torch.tensor(class_weights).to(device)\n",
    "cls_loss_fn = nn.BCELoss(weight)\n",
    "# class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd01dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## cosine similarity loss w.r.t comment\n",
    "cos_dis_loss_fn = nn.CosineEmbeddingLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bacf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## contrastive loss\n",
    "con_loss_fn = losses.SupConLoss(temperature=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1be625",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn_dict = {\n",
    "    \"cls_loss_fn\": cls_loss_fn,\n",
    "    \"cos_dis_loss_fn\": cos_dis_loss_fn,\n",
    "    \"con_loss_fn\": con_loss_fn\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c0136c",
   "metadata": {},
   "source": [
    "### Learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecab526",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_lr_param_list = ['grade_classifier']\n",
    "\n",
    "low_lr_params = list(filter(\n",
    "    lambda kv: sum([_name in kv[0] for _name in low_lr_param_list]),\n",
    "    pHAN.named_parameters()\n",
    "))\n",
    "low_lr_params = [params[1] for params in low_lr_params]\n",
    "\n",
    "base_lr_params = list(filter(\n",
    "    lambda kv: sum([_name not in kv[0] for _name in low_lr_param_list]),\n",
    "    pHAN.named_parameters()\n",
    "))\n",
    "base_lr_params = [params[1] for params in base_lr_params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206936db",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_learning_rate = 1e-3\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    [\n",
    "        {\"params\": base_lr_params, \"lr\": 1e-3},\n",
    "        {\"params\": low_lr_params, \"lr\": 1e-3},\n",
    "        {\"params\": torch.tensor([1]), \"lr\": 1}, ## eta\n",
    "    ],\n",
    "    lr=base_learning_rate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125d47e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_gamma = 0.8\n",
    "step_size = 8\n",
    "sch_lambda_params = lambda epoch: lr_gamma ** (epoch // step_size)\n",
    "sch_lambda_eta = lambda epoch: max(0, 1 - 0.1 * (epoch // 1 // step_size))\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
    "    optimizer, lr_lambda=[sch_lambda_params, sch_lambda_params, sch_lambda_eta]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef5ade7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in range(100):\n",
    "#     print(epoch, scheduler.get_last_lr())\n",
    "#     scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad98a64",
   "metadata": {},
   "source": [
    "## Load state of the model, optimizer, and scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f2d3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(t):\n",
    "    ## find model name\n",
    "    model_name = \"epoch_{:04d}.pt\".format(t)\n",
    "    fn = os.path.join(MODEL_SAVE_DIR_PATH, model_name)\n",
    "    checkpoint = torch.load(fn)\n",
    "    \n",
    "    pHAN.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bc327f",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model(EPOCH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90600a3",
   "metadata": {},
   "source": [
    "# Generate summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba086dd",
   "metadata": {},
   "source": [
    "## Calculate attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea02ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6469aae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_perspective_sent_distribution(att):\n",
    "    sent_dist = [math.floor(MAX_SENT * a) for a in att]\n",
    "    \n",
    "    ## find perspective above threshold\n",
    "#     for i, a in enumerate(att):\n",
    "#         if a > PERSPECTIVE_ATT_MIN_THRESHOLD and math.floor(MAX_SENT * a) == 0:\n",
    "#             sent_dist[i] = 1\n",
    "    \n",
    "    while sum(sent_dist) < MAX_SENT:\n",
    "        add_sent_cand = [(d, 1-a, i) for i, (d, a) in enumerate(zip(sent_dist, att))]\n",
    "        sorted_add_sent_cand = sorted(add_sent_cand)\n",
    "        \n",
    "        ## add sent quota to the first candidate\n",
    "        pers_to_add_sent = sorted_add_sent_cand[0][2]\n",
    "        sent_dist[pers_to_add_sent] += 1\n",
    "        \n",
    "    return sent_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef8d37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_dict = {}\n",
    "\n",
    "def summary_generation_loop(dataloader, model):\n",
    "    eta = 0\n",
    "    \n",
    "    batch_num = len(dataloader.dataset) // BATCH_SIZE\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, total=batch_num):\n",
    "            model.eval()\n",
    "            \n",
    "            batch_infos, batch_pseudo_summaries, batch_comments, batch_grades = get_data(batch)\n",
    "            \n",
    "            # Compute prediction\n",
    "            _, _, sent_att, pers_att = model(batch_pseudo_summaries, batch_comments, eta)\n",
    "            \n",
    "            for applicant_info, pseudo_summary, s_att, p_att in zip(batch_infos, batch_pseudo_summaries, sent_att, pers_att):\n",
    "                applicant_info = tuple(applicant_info)\n",
    "                \n",
    "                attention_dict[applicant_info] = {\n",
    "                    'pseudo_summary': pseudo_summary,\n",
    "                    'sent_att': s_att.detach().cpu().numpy(),\n",
    "                    'pers_att': p_att.detach().cpu().numpy(),\n",
    "                }\n",
    "                \n",
    "#                 print(applicant_info)\n",
    "#                 print(\"sent_att: \", s_att)\n",
    "#                 print(\"pers_att: \", p_att)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32daa9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_generation_loop(test_dataloader, pHAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de71a4f6",
   "metadata": {},
   "source": [
    "## Generate summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b47539b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = os.path.join(\n",
    "    P.FP_COMMENT_CLUSTERING_TOPIC_HIERARCHY_DIR, \n",
    "    \"{}_topic_aggregate_info.pkl\".format(BERTOPIC_MODEL_NAME)\n",
    ")\n",
    "\n",
    "with open(fn, \"rb\") as f:\n",
    "    topic_aggregate_info = pickle.load(f)\n",
    "    topic_aggregate_dict = topic_aggregate_info['topic_aggregate_dict']\n",
    "    perspective_mean_embed_dict = topic_aggregate_info['topic_aggregate_embed_mean_dict']\n",
    "    topic_aggregate_intra_similarity_dict = topic_aggregate_info['topic_aggregate_intra_similarity_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dd9f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_aggregate_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35af52db",
   "metadata": {},
   "source": [
    "## Calculate the quota for each perspective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315b6862",
   "metadata": {},
   "outputs": [],
   "source": [
    "quota_list = [3, 2, 2, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3dac4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, pids in topic_aggregate_dict.items():\n",
    "#     print(i, pids)\n",
    "#     print(topic_aggregate_intra_similarity_dict[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb461ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "quota_dict = {}\n",
    "\n",
    "for i, (pid, _) in enumerate(sorted(topic_aggregate_intra_similarity_dict.items(), key=lambda l: l[1])):\n",
    "    quota_dict[pid] = quota_list[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34f292c",
   "metadata": {},
   "outputs": [],
   "source": [
    "quota_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acef777",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.util import cos_sim\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64113b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SBERT_MODEL_NAME = 'ckiplab/bert-base-chinese'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bcde2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert_model = SentenceTransformer(SBERT_MODEL_NAME).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d7b916",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from itertools import chain\n",
    "from collections import Counter, OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d603c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "perspective_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bd862c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_is_redundency(sent, summary_buf, redundency_threshold=0.9, quota=2, debug=False):\n",
    "    ## [TODO] adjust the quota based on the diversity of the perspective\n",
    "    sent_embed = sbert_model.encode(sent, batch_size=64, show_progress_bar=False)\n",
    "    summary_buf_embed = sbert_model.encode(summary_buf, batch_size=64, show_progress_bar=False)\n",
    "    \n",
    "    sims = cosine_similarity([sent_embed], summary_buf_embed)[0]\n",
    "    \n",
    "    if debug:\n",
    "        print(\"similarity:\", sims)\n",
    "        \n",
    "    num_sim_sent = sum(sims > redundency_threshold)\n",
    "    \n",
    "    return num_sim_sent >= quota"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20377bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17678b1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "summary_dict = {}\n",
    "\n",
    "for info, _dict in tqdm(attention_dict.items()):\n",
    "#     print(info)\n",
    "    \n",
    "    pseudo_summary = _dict['pseudo_summary']\n",
    "    sent_att = _dict['sent_att']\n",
    "    pers_att = _dict['pers_att']\n",
    "    rls = list(rl_info_dict[info[:2]].keys())\n",
    "#     print(rls)\n",
    "\n",
    "    ## get_perspective_sent_distribution\n",
    "#     print(pers_att)\n",
    "    pers_sent_dist = get_perspective_sent_distribution(pers_att)\n",
    "#     print(pers_sent_dist)\n",
    "\n",
    "    summary = defaultdict(list)\n",
    "    title_weight = defaultdict(float)\n",
    "    \n",
    "    sent_combine_att_dict = {}\n",
    "    sent_info_dict = {}\n",
    "    \n",
    "    for i, (pers_sent, s_att, p_att) in enumerate(zip(pseudo_summary, sent_att, pers_att)):\n",
    "        for sent, _s_att in zip(pers_sent, s_att):\n",
    "            ## [TODO] if sent evidence score is 0, boost the weight by a small factor\n",
    "            boost_weight = 1.0\n",
    "            if sent in rls:\n",
    "                boost_weight = RL_WEIGHT_BOOST\n",
    "            \n",
    "            sent_combine_att_dict[sent] = p_att * _s_att * boost_weight\n",
    "            sent_info_dict[sent] = {\n",
    "                \"pers\": i,\n",
    "                \"pers_att\": p_att,\n",
    "                \"sent_att\": _s_att,\n",
    "                \"cmb_att\": p_att * _s_att * boost_weight\n",
    "            }\n",
    "            \n",
    "    ## generate summary from the highest combined attention sentence\n",
    "    summary_str_buf = [\"\"]\n",
    "    summary_pers_sent_count = Counter()\n",
    "    for num_sent, (sent, cmb_att) in enumerate(sorted(sent_combine_att_dict.items(), key=lambda i: -i[1])):\n",
    "        ## check if sent count exceed the limit\n",
    "        if len(summary_str_buf) >= MAX_SENT:\n",
    "            break\n",
    "        \n",
    "        pers_id = sent_info_dict[sent]['pers']\n",
    "        pers_num_sent_in_summary = summary_pers_sent_count[pers_id]\n",
    "        ## check if combined att is lower then threshold\n",
    "        if cmb_att < COMBINED_ATT_MIN_THRESHOLD - pers_num_sent_in_summary * ATT_THRESHOLD_DECAY:\n",
    "            continue\n",
    "        ## check if the sentence in the perspective is already full\n",
    "        if summary_pers_sent_count[pers_id] >= quota_dict[pers_id]:\n",
    "            continue\n",
    "        ## check if the added sent is too similar to the sentence already in the summary\n",
    "        if check_is_redundency(sent, summary_str_buf, quota=quota_dict[pers_id]):\n",
    "            continue\n",
    "        \n",
    "        ## add the sentence to the summary\n",
    "        pers_id = sent_info_dict[sent]['pers']\n",
    "        title = perspective_title[pers_id]\n",
    "        summary[title] += [sent]\n",
    "        title_weight[title] += cmb_att\n",
    "        summary_pers_sent_count[pers_id] += 1\n",
    "        summary_str_buf.append(sent)\n",
    "    \n",
    "    summary_dict[info] = {\n",
    "        \"summary\": summary,\n",
    "        \"title_weight\": title_weight,\n",
    "    }\n",
    "    \n",
    "    ## generate debug info\n",
    "    doc = Document()\n",
    "    ## info about cmb_att ranking list\n",
    "#     _ = doc.add_heading(\"Combined attention weight ranking list\", level=2)\n",
    "#     for num_sent, (sent, cmb_att) in enumerate(sorted(sent_combine_att_dict.items(), key=lambda i: -i[1])):\n",
    "#         _ = doc.add_paragraph(\"rank: {}, cmb_att: {:.4f}, sent: {}\".format(\n",
    "#             num_sent+1, cmb_att, sent\n",
    "#         ))\n",
    "    \n",
    "#     _ = doc.add_page_break()\n",
    "    ## info about detailed attention weight list\n",
    "    _ = doc.add_heading(\"Detailed attention weight per sentence\", level=2)\n",
    "    for num_sent, (sent, _) in enumerate(sorted(sent_combine_att_dict.items(), key=lambda i: -i[1])):\n",
    "        weights = sent_info_dict[sent]\n",
    "        _ = doc.add_paragraph(\"rank: {}, cmb_att: {:.4f}, pers: {}, pers_att: {:.4f}, sent_att: {:.4f}, sent: {}\".format(\n",
    "            num_sent+1, weights['cmb_att'], weights['pers'], weights['pers_att'], weights['sent_att'], sent\n",
    "        ))\n",
    "        \n",
    "    _ = doc.add_page_break()\n",
    "    ## info about attention weight per perspective\n",
    "    _ = doc.add_heading(\"Sentence attention per perspective\", level=2)\n",
    "    for i, (pers_sent, s_att, p_att) in enumerate(zip(pseudo_summary, sent_att, pers_att)):\n",
    "        _ = doc.add_paragraph(\"perspective {} attention weight: {}\".format(i, p_att))\n",
    "        for _idx in np.argsort(s_att)[::-1]:\n",
    "            _ = doc.add_paragraph(\"pers_att: {:4f}, sent: {}\".format(s_att[_idx], pers_sent[_idx]))\n",
    "            \n",
    "        _ = doc.add_paragraph(\"=\"*50)\n",
    "        \n",
    "    fn = \"{}_att_weight_debug.docx\".format(\"_\".join(map(str, info)))\n",
    "    _ = doc.save(os.path.join(summary_debug_dir, fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88025555",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c6e3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456cd595",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_summary_dict = os.path.join(summary_docx_dir, \"summary_dict.pkl\")\n",
    "\n",
    "with open(fn_summary_dict, 'wb') as f:\n",
    "    pickle.dump(summary_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a4e4ae",
   "metadata": {},
   "source": [
    "## Calculate BERTScore with corresponding comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5b1502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## find summary and its corresponding comment\n",
    "# if VAL_OR_TEST == 'val':\n",
    "#     test_summary_result = []\n",
    "\n",
    "#     for applicant_info, pseudo_summary, comment in zip(test_info_data, test_pseudo_summary_data, test_comment_data):\n",
    "#         applicant_info = tuple(applicant_info)\n",
    "#         summary = summary_dict[applicant_info]['summary']\n",
    "#         buffer = []\n",
    "\n",
    "#         for sents in summary.values():\n",
    "#             buffer.append(sents)\n",
    "\n",
    "#         summary = ''.join(list(chain.from_iterable(buffer)))\n",
    "\n",
    "#         # concat summary together [TODO] different concata method may result in differenet bertscore?\n",
    "#         test_summary_result.append(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19a8e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if VAL_OR_TEST == 'val':\n",
    "#     from bert_score import score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412de919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_bert_score(cands, refs, rescale=False, verbose=False):\n",
    "#     return score(\n",
    "#         cands,\n",
    "#         refs,\n",
    "#         lang=\"zh\",\n",
    "#     #     model_type=MODEL_TYPE,\n",
    "#     #     num_layers=LAYER,\n",
    "#         verbose=verbose,\n",
    "#         device=0,\n",
    "#         batch_size=64,\n",
    "#     #     idf=False,\n",
    "#         rescale_with_baseline=rescale\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39045629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if VAL_OR_TEST == 'val':\n",
    "#     _P, _R, _F1 = calculate_bert_score(test_summary_result, test_comment_data, rescale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c067ef4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d5da1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if VAL_OR_TEST == 'val':\n",
    "#     IO.log_dividing_line(logger)\n",
    "#     logger.info(\"model dir: {}\".format(MODEL_SAVE_DIR_NAME))\n",
    "#     logger.info(\"time: {}\".format(str(datetime.now())))\n",
    "#     logger.info(\"combined att method\")\n",
    "#     logger.info(\"epoch: {}\".format(EPOCH))\n",
    "#     logger.info(\"max sent: {}\".format(MAX_SENT))\n",
    "#     logger.info(\"cmb att threshold: {}\".format(COMBINED_ATT_MIN_THRESHOLD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e79fa4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if VAL_OR_TEST == 'val':\n",
    "#     rouge_precision = torch.mean(_P)\n",
    "#     rouge_recall = torch.mean(_R)\n",
    "#     rouge_f1 = torch.mean(_F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2e0e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if VAL_OR_TEST == 'val':\n",
    "#     logger.info(\"p: {:4f}\".format(rouge_precision))\n",
    "#     logger.info(\"r: {:4f}\".format(rouge_recall))\n",
    "#     logger.info(\"f: {:4f}\".format(rouge_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78432a1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research_venv",
   "language": "python",
   "name": "research_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
