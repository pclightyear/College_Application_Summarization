{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress: \")\n",
    "\n",
    "from importlib import reload\n",
    "\n",
    "# Utility variable\n",
    "import sys\n",
    "sys.path.insert(0, '../..')\n",
    "\n",
    "# var\n",
    "import var.var as V\n",
    "import var.path as P\n",
    "\n",
    "# utils\n",
    "import utils.data as D\n",
    "import utils.io as IO\n",
    "import utils.mmr as MMR\n",
    "import utils.preprocess as PP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def defaultdict_init_defaultdict_init_by_int():\n",
    "    return defaultdict(int)\n",
    "\n",
    "def defaultdict_init_defaultdict_init_by_float():\n",
    "    return defaultdict(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_OR_ALL = 'all'\n",
    "BERTOPIC_MODEL_NAME = \"BERTopic_custom_mcs_100_ckip_diversified_low_{}\".format(TRAIN_OR_ALL)\n",
    "TOP_K = V.TOP_K\n",
    "MAX_SENT_PER_TOPIC = 3\n",
    "SIM_THRESHOLD = 0.94"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = os.path.join(\n",
    "    P.FP_COMMENT_CLUSTERING_TOPIC_HIERARCHY_DIR, \n",
    "    \"{}_topic_aggregate_info.pkl\".format(BERTOPIC_MODEL_NAME)\n",
    ")\n",
    "\n",
    "with open(fn, \"rb\") as f:\n",
    "    topic_aggregate_info = pickle.load(f)\n",
    "    topic_aggregate_dict = topic_aggregate_info['topic_aggregate_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_aggregate_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "topic_to_aggregate_topic_dict = {}\n",
    "\n",
    "for agg_tid, tids in topic_aggregate_dict.items():\n",
    "    for tid in tids:\n",
    "        topic_to_aggregate_topic_dict[tid] = agg_tid\n",
    "        \n",
    "topic_to_aggregate_topic_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate pseudo summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU_NUM = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(GPU_NUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.util import cos_sim\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SBERT_MODEL_NAME = 'ckiplab/bert-base-chinese'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert_model = SentenceTransformer(SBERT_MODEL_NAME).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from itertools import chain\n",
    "from collections import Counter, OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mmr_sorted(docs, q, lambda_=0.3):\n",
    "    def mmr_sim1(x, q):\n",
    "        \"\"\"\n",
    "            q is the pre-computed score dictionary for each x\n",
    "        \"\"\"\n",
    "        return q[x]\n",
    "\n",
    "    def mmr_sim2(x, y, sim_mat):\n",
    "        _idx_x = doc_to_idx[x]\n",
    "        _idx_y = doc_to_idx[y]\n",
    "        return sim_mat[_idx_x, _idx_y]\n",
    "    \n",
    "    def argmax(keys, f):\n",
    "        return max(keys, key=f)\n",
    "    \n",
    "    if len(docs) == 0:\n",
    "        return {}\n",
    "    \n",
    "    docs_embed = sbert_model.encode(docs, batch_size=512, show_progress_bar=False)\n",
    "    sim_mat = cosine_similarity(docs_embed, docs_embed)\n",
    "    doc_to_idx = {doc: i for i, doc in enumerate(docs)}\n",
    "    \n",
    "    docs = set(docs)\n",
    "    \n",
    "    selected = OrderedDict() \n",
    "    while set(selected) != docs: \n",
    "        remaining = docs - set(selected) \n",
    "        mmr_score = lambda x: lambda_*mmr_sim1(x, q) - (1-lambda_)*max([mmr_sim2(x, y, sim_mat) for y in set(selected)-{x}] or [0]) \n",
    "        next_selected = argmax(remaining, mmr_score) \n",
    "        selected[next_selected] = len(selected) \n",
    "    \n",
    "    return selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_idx = [\n",
    "    \"# The content is removed due to confidential concerns.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_summary_dir = os.path.join(P.FP_SIGNIFICANCE_PSEUDO_SUMMARY_DIR, 'custom_bertopic', TRAIN_OR_ALL)\n",
    "all_data_dir = os.path.join(pseudo_summary_dir, 'all_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "\n",
    "for file in tqdm(os.listdir(all_data_dir)):\n",
    "    fn = os.path.join(all_data_dir, file)\n",
    "    \n",
    "#     IO.print_dividing_line()\n",
    "    # [TODO] remember to remove testing data\n",
    "#     if i >= 1:\n",
    "#         break\n",
    "    if 'experiment' not in fn:\n",
    "        continue\n",
    "    \n",
    "    if os.path.isdir(fn):\n",
    "        continue\n",
    "        \n",
    "    print(fn)\n",
    "        \n",
    "    with open(fn, \"rb\") as f:\n",
    "        group_data = pickle.load(f)\n",
    "\n",
    "    ## process group data\n",
    "    candidate_sents_info_buffer = group_data[\"candidate_sents_info_buffer\"]\n",
    "    chunk_debug_info_buffer = group_data[\"chunk_debug_info_buffer\"]\n",
    "\n",
    "#     print(candidate_sents_info_buffer)\n",
    "#     print(chunk_debug_info_buffer)\n",
    "    \n",
    "    ## extract pseudo summary\n",
    "    for _idx, info in candidate_sents_info_buffer.items():\n",
    "        cnt += 1\n",
    "        \n",
    "        _year = _idx[0]\n",
    "        _id = _idx[1]\n",
    "        _name = _idx[2]\n",
    "        \n",
    "        if _year != 112:\n",
    "            continue\n",
    "        \n",
    "        if debug and _idx not in test_idx:\n",
    "            continue\n",
    "\n",
    "        if debug:\n",
    "            print(_idx)\n",
    "            \n",
    "        sents = info['sents']\n",
    "        topic_sent_dict = info['topic_sent_dict']\n",
    "        sents_topic_importance_dict = info['sents_topic_importance_dict']\n",
    "        sents_avg_importance_dict = info['sents_avg_importance_dict']\n",
    "        ## mmr score scaling\n",
    "        sents_avg_importance_dict = {k: 2*v for k, v in sents_avg_importance_dict.items()}\n",
    "        \n",
    "        chunk_debug_info = chunk_debug_info_buffer[_idx]\n",
    "\n",
    "        ## pseudo summary as list of perspectives of sentences\n",
    "        pseudo_summary = []\n",
    "        \n",
    "        ## Significance: select top-k sentence for each aggregated perspective\n",
    "        sents_aggregate_perspective_dict = defaultdict(list)\n",
    "        ## Find the candidate sentences for each aggregated perspective\n",
    "        ## One sentence can only belong to one aggregated perspective (with highest important score)\n",
    "        for sent in sents:\n",
    "            sent_agg_pers_imp_dict = defaultdict(float)\n",
    "            topic_importance_dict = sents_topic_importance_dict[sent]\n",
    "            \n",
    "            for tid, imp in topic_importance_dict.items():\n",
    "                if tid == -1:\n",
    "                    continue\n",
    "                agg_pers_id = topic_to_aggregate_topic_dict[tid]\n",
    "                sent_agg_pers_imp_dict[agg_pers_id] += imp\n",
    "                \n",
    "            if sent_agg_pers_imp_dict == {}:\n",
    "                continue\n",
    "                \n",
    "            belong_agg_pers_id = max(sent_agg_pers_imp_dict, key=sent_agg_pers_imp_dict.get)\n",
    "            ## append the candidate sentence to the perspective with highest importance score\n",
    "            sents_aggregate_perspective_dict[belong_agg_pers_id].append(sent)\n",
    "            \n",
    "        ## select sentences from each aggregated perspective\n",
    "        for agg_pers_id, _ in topic_aggregate_dict.items():\n",
    "#             perspective_sent = sents_aggregate_perspective_dict[agg_pers_id] ## select all sentences\n",
    "            perspective_sent = [''] * TOP_K ## pad empty sentence\n",
    "            candidate_sent = sents_aggregate_perspective_dict[agg_pers_id]\n",
    "            \n",
    "            # apply mmr\n",
    "            sent_mmr_sorted = mmr_sorted(candidate_sent, sents_avg_importance_dict)\n",
    "            \n",
    "            for i, sent in enumerate(sent_mmr_sorted.keys()):\n",
    "                if i >= len(perspective_sent):\n",
    "                    break\n",
    "                perspective_sent[i] = sent\n",
    "            pseudo_summary.append(perspective_sent)\n",
    "        \n",
    "        if debug:\n",
    "            IO.print_dividing_line()\n",
    "        \n",
    "        if debug:\n",
    "            print(\"before remove similar sentences\")\n",
    "            print(pseudo_summary)\n",
    "            IO.print_dividing_line()\n",
    "        \n",
    "        ## within each perspective, remove sentence with too similar semantic meaning (> 0.95)\n",
    "        for pers_id, pers_sents in enumerate(pseudo_summary):\n",
    "            if debug:\n",
    "                print(\"pers id: \", pers_id)\n",
    "            pers_sent_embeds = sbert_model.encode(pers_sents, show_progress_bar=False)\n",
    "            sim_mat = cos_sim(pers_sent_embeds, pers_sent_embeds)\n",
    "            \n",
    "            similar_pair = []\n",
    "            \n",
    "            for i, j in combinations(range(TOP_K), 2):\n",
    "                if sim_mat[i, j] > SIM_THRESHOLD:\n",
    "                    similar_pair.append((i, j))\n",
    "            \n",
    "            remove_sent_id_buf = []\n",
    "            ## remove the shorter sentence\n",
    "            for i, j in similar_pair:\n",
    "                if pers_sents[i] == '' and pers_sents[j] == '':\n",
    "                    continue\n",
    "                    \n",
    "                if debug:\n",
    "                    print(pers_sents[i])\n",
    "                    print(pers_sents[j])\n",
    "                    IO.print_dividing_line()\n",
    "                len_i = PP.get_sent_len(pers_sents[i])\n",
    "                len_j = PP.get_sent_len(pers_sents[j])\n",
    "                \n",
    "                if len_j > len_i:\n",
    "                    remove_sent_id_buf.append(i)\n",
    "                else:\n",
    "                    remove_sent_id_buf.append(j)\n",
    "            \n",
    "            for i in remove_sent_id_buf:\n",
    "                pseudo_summary[pers_id][i] = ''\n",
    "        \n",
    "        if debug:\n",
    "            print(\"after remove similar sentences\")\n",
    "            print(pseudo_summary)\n",
    "            IO.print_dividing_line()\n",
    "            \n",
    "        if not debug:\n",
    "            write_buffer = {\n",
    "                \"year\": _year,\n",
    "                \"id\": _id,\n",
    "                \"name\": _name,\n",
    "                \"pseudo_summary\": pseudo_summary\n",
    "            }\n",
    "\n",
    "            fn = \"{}.pkl\".format(\"_\".join(map(str, [_year, _id])))\n",
    "            fp = os.path.join(pseudo_summary_dir, str(_year), fn)\n",
    "\n",
    "            with open(fp, \"wb\") as f:\n",
    "                pickle.dump(write_buffer, f)\n",
    "    \n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_summary_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research_venv",
   "language": "python",
   "name": "research_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
