{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f564250",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product, chain\n",
    "from joblib import Parallel, delayed\n",
    "from collections import Counter\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress: \")\n",
    "\n",
    "from importlib import reload\n",
    "import pickle\n",
    "\n",
    "# Utility variable\n",
    "import sys, getopt\n",
    "sys.path.insert(0, '../..')\n",
    "\n",
    "# var\n",
    "import var.var as V\n",
    "import var.path as P\n",
    "\n",
    "# utils\n",
    "import utils.data as D\n",
    "import utils.io as IO\n",
    "import utils.preprocess as PP\n",
    "import utils.torch as Tor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230c5a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc42cc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TOKENIZERS_PARALLELISM']= 'false'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af86f650",
   "metadata": {},
   "source": [
    "## Process Command Line Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad61fe33",
   "metadata": {},
   "outputs": [],
   "source": [
    "opts, args = getopt.getopt(sys.argv[1:], \"af:r:n:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8046fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_OR_ALL = 'train'\n",
    "BATCH_SIZE = 70\n",
    "RADIUS = 7.5\n",
    "N_NEIGHBORS = 30\n",
    "\n",
    "for opt, arg in opts:\n",
    "    if opt == '-a':\n",
    "        TRAIN_OR_ALL = 'all'\n",
    "    elif opt == '-r':\n",
    "        RADIUS = float(arg)\n",
    "    elif opt == '-n':\n",
    "        N_NEIGHBORS = int(arg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5cd8f1",
   "metadata": {},
   "source": [
    "## Read data\n",
    "- need to know which comment chunk belong to which applicant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f018d82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_applicants = D.read_df_applicants(TRAIN_OR_ALL)\n",
    "df_comments = D.read_df_comments()\n",
    "df_split_comments = D.read_df_split_comments_no_duplicate(TRAIN_OR_ALL)\n",
    "split_comments = D.read_split_comments_no_duplicate(TRAIN_OR_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d83d666",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_comment_to_id = {sc: idx for idx, sc in zip(df_split_comments['split_comment'].index, df_split_comments['split_comment'].values)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa006c7",
   "metadata": {},
   "source": [
    "## Find original applicant for each split comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2beb355",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "sc_applicant_lists = df_split_comments['applicants']\n",
    "sc_committee_lists = df_split_comments['committee']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03afca3",
   "metadata": {},
   "source": [
    "## Load the  embedding and the topics of each split comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8df29a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "import utils.bertopic as BT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f07c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d46e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "_pass = BT._pass\n",
    "topic_doc_tokenizer = BT.topic_doc_tokenizer\n",
    "vectorizer = CountVectorizer(tokenizer=topic_doc_tokenizer, lowercase=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f84d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "SBERT_MODEL_NAME = 'ckiplab/bert-base-chinese'\n",
    "\n",
    "if TRAIN_OR_ALL == 'train':\n",
    "    BERTOPIC_MODEL_NAME = \"BERTopic_custom_mcs_100_ckip_diversified_low_train\"\n",
    "elif TRAIN_OR_ALL == 'all':\n",
    "    BERTOPIC_MODEL_NAME = \"BERTopic_custom_mcs_100_ckip_diversified_low_all\"\n",
    "    \n",
    "SPLITTER = '＄'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84da21a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model = BERTopic.load(os.path.join(P.FP_COMMENT_CLUSTERING_MODEL_DIR, BERTOPIC_MODEL_NAME))\n",
    "print(\"Load BERTopic model success.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d922526",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert_model = topic_model.embedding_model.embedding_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e38509",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tokenization_database = df_split_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11265815",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_bert = topic_model.embedding_model.embedding_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee72740",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_comments_embeds = sentence_bert.encode(split_comments, show_progress_bar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d320e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_split_comments_embeds = topic_model.umap_model['umap'].embedding_\n",
    "reduced_split_comments_embeds = topic_model.umap_model['norm'].transform(reduced_split_comments_embeds)\n",
    "reduced_split_comments_embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0274536",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hdbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb65523",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, probs = hdbscan.approximate_predict(\n",
    "    topic_model.hdbscan_model, reduced_split_comments_embeds\n",
    ")\n",
    "topics = topic_model.hdbscan_model.labels_\n",
    "\n",
    "topics = topic_model._map_predictions(topics)\n",
    "probs = topic_model._map_probabilities(probs, original_topics=True)\n",
    "topic_labels = topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ee2693",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic(s):\n",
    "    idx = split_comments.index(s)\n",
    "    return topics[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabb63c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15850af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.util import cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ec3f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "split_comments_sim_mat = cos_sim(split_comments_embeds, split_comments_embeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1fea39",
   "metadata": {},
   "source": [
    "## comments embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182f1385",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = []\n",
    "app_comments_idx_dict = defaultdict(list)\n",
    "\n",
    "for _, row in df_comments.iterrows():\n",
    "    _year = row['year']\n",
    "    _id = row['id']\n",
    "    comment = row['comment']\n",
    "    \n",
    "    if PP.is_empty_sent(comment):\n",
    "        continue\n",
    "    \n",
    "    app_comments_idx_dict[(_year, _id)].append(len(comments))\n",
    "    comments.append(comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553cfaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_embeds = sentence_bert.encode(comments, show_progress_bar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd18690",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_comments_and_comments_sim_mat = cos_sim(split_comments_embeds, comments_embeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4e55f4",
   "metadata": {},
   "source": [
    "## Calculate chunk consensus for each applicant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17635632",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_row_data_list = []\n",
    "\n",
    "for _, row in df_split_comments.iterrows():\n",
    "    sc = row['split_comment']\n",
    "    committee = row['committee']\n",
    "    \n",
    "#     print(sc, committee)\n",
    "    \n",
    "    for com in committee:\n",
    "        chunk_row_data = {\n",
    "            \"year\": com[0],\n",
    "            \"id\": com[1],\n",
    "            \"committee_number\": com[2],\n",
    "            \"split_comment\": sc\n",
    "        }\n",
    "        chunk_row_data_list.append(chunk_row_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2868170",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chunk = pd.DataFrame(chunk_row_data_list)\n",
    "df_chunk.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50402da",
   "metadata": {},
   "source": [
    "## Find the committee that does not write comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095cd14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comment_committee_group = df_comments.groupby(['year', 'group', 'committee_number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531af294",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_comment_rate_threshold = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2f4aee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "committee_empty_comment_rate_dict = {}\n",
    "empty_comment_committee_list = []\n",
    "\n",
    "for committee, g in df_comment_committee_group:\n",
    "    comment_cnt = g.shape[0]\n",
    "    \n",
    "    empty_comment_cnt = 0\n",
    "#     comments = []\n",
    "    for comment in g['comment']:\n",
    "        if PP.is_empty_sent(comment):\n",
    "            empty_comment_cnt += 1\n",
    "#         else:\n",
    "#             comments.append(comment)\n",
    "    \n",
    "    empty_comment_rate = empty_comment_cnt / comment_cnt\n",
    "    print(committee, \"empty_comment_rate: {:.3f}\".format(empty_comment_rate))\n",
    "    committee_empty_comment_rate_dict[committee] = empty_comment_rate\n",
    "    \n",
    "    if empty_comment_rate > empty_comment_rate_threshold:\n",
    "        empty_comment_committee_list.append(committee)\n",
    "    \n",
    "#     # calculate comment diversity\n",
    "#     embeds = sentence_bert.encode(comments, show_progress_bar=False)\n",
    "#     sim_mat = np.array(cos_sim(embeds, embeds))\n",
    "#     mean_similarity = np.mean((np.sum(sim_mat, axis=-1) - 1) / (len(comments) - 1))\n",
    "#     print(committee, \"mean_similarity: {:.3f}\".format(mean_similarity))\n",
    "#     print(comments)\n",
    "    \n",
    "#     IO.print_dividing_line()\n",
    "    \n",
    "#     print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acd7ab5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sorted(committee_empty_comment_rate_dict.items(), key=lambda item: -item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8935f337",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_comment_committee_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dad97d4",
   "metadata": {},
   "source": [
    "## Calculate the number of committee per group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87546135",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_applicant_group = df_comments.groupby(['year', 'group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4e0d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_group_committee_count = {}\n",
    "\n",
    "for app_group, g in df_applicant_group:\n",
    "#     num_committee = g.groupby(['committee_number']).ngroups\n",
    "    group_committee = g.groupby(['committee_number']).groups.keys()\n",
    "    num_committee = sum([1 for com in group_committee if (*app_group, com) not in empty_comment_committee_list ])\n",
    "    \n",
    "    app_group_committee_count[app_group] = num_committee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b92c593",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_group_committee_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314a6d7c",
   "metadata": {},
   "source": [
    "## Find neighbors by BERTScore\n",
    "1. Find the neighbors based on r or k\n",
    "2. Calculate BERTScore and filter neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b51f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "RADIUS = 7.5\n",
    "N_NEIGHBORS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7a9705",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c991c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh = NearestNeighbors(metric='minkowski') ## or 'cosine'\n",
    "neigh.fit(split_comments_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b11a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "r_neigh_dist, r_neighbor_ind = neigh.radius_neighbors(split_comments_embeds, RADIUS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec766477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %%time\n",
    "k_neigh_dist, k_neighbor_ind = neigh.kneighbors(split_comments_embeds, N_NEIGHBORS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9299d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_neighbor_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029a1258",
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh_count_within_r = np.array([len(neighbor_ind) for neighbor_ind in r_neighbor_ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20f0399",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.sort(neigh_count_within_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441f9622",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_neighbor_distance = []\n",
    "sc_neighbor_index = []\n",
    "\n",
    "for rnd, rni, knd, kni in zip(r_neigh_dist, r_neighbor_ind, k_neigh_dist, k_neighbor_ind):\n",
    "    ## apply k nearest neighbors\n",
    "    if len(rni) < N_NEIGHBORS:\n",
    "        sc_neighbor_distance.append(rnd)\n",
    "        sc_neighbor_index.append(rni)\n",
    "    else:\n",
    "        sc_neighbor_distance.append(rnd)\n",
    "        sc_neighbor_index.append(rni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12dcda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbor_count = np.array([len(nind) for nind in sc_neighbor_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240b116b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.sort(neighbor_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ba1791",
   "metadata": {},
   "source": [
    "## Aggregate the referred applicants of all neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca99de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "print(\"aggregate the referred applicants of all neighbors...\")\n",
    "\n",
    "applicants_of_neighbor = []\n",
    "committees_of_neighbor = []\n",
    "\n",
    "for nind in tqdm(filtered_sc_neighbor_index):\n",
    "    applicants = set()\n",
    "    committees = set()\n",
    "    \n",
    "    for nidx in nind:\n",
    "        sc_applicants = sc_applicant_lists.iloc[nidx]\n",
    "        sc_committees = sc_committee_lists.iloc[nidx]\n",
    "        \n",
    "        for app in sc_applicants:\n",
    "            applicants.add(app)\n",
    "            \n",
    "        for com in sc_committees:\n",
    "            committees.add(com)\n",
    "            \n",
    "    applicants_of_neighbor.append(applicants)\n",
    "    committees_of_neighbor.append(committees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e8f790",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighbor(sc, debug=False):\n",
    "    idx = split_comments.index(sc)\n",
    "    print(idx)\n",
    "    row = df_chunk.query(\"`split_comment` == @sc\")\n",
    "    print(row)\n",
    "    \n",
    "    print(\"split comment:\", split_comments[idx])\n",
    "    print(\"Neighbors:\")\n",
    "    \n",
    "    for nidx in filtered_sc_neighbor_index[idx]:\n",
    "        if debug:\n",
    "            print(\"\\\"{}\\\",\".format(split_comments[nidx]))\n",
    "        else:\n",
    "#             print('  ', split_comments[nidx])\n",
    "            print('  ', nidx, sc_applicant_lists.iloc[nidx], split_comments[nidx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b384b801",
   "metadata": {},
   "source": [
    "## Calculate uniqueness score\n",
    "- inverse applicant frequency\n",
    "- consensus rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7c8dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_applicants = df_applicants.shape[0]\n",
    "df_comment_applicant_group = df_comments.groupby(['year', 'id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05540995",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_committee_count = {}\n",
    "\n",
    "for _, row in df_comments.iterrows():\n",
    "    app = (row['year'], row['id'])\n",
    "    committee_count = app_group_committee_count[(row['year'], row['group'])] \n",
    "    \n",
    "    app_committee_count[app] = committee_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e72321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neigh_app, neigh_com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003c697e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"calculate uniqueness score...\")\n",
    "\n",
    "split_comments_uniqueness = []\n",
    "split_comments_iaf = []\n",
    "# split_comments_iccr = []\n",
    "split_comments_ccr = []\n",
    "\n",
    "split_comments_iaf_dict = {}\n",
    "\n",
    "for idx, (sc, neigh_app, neigh_com) in tqdm(enumerate(zip(split_comments, applicants_of_neighbor, committees_of_neighbor))):\n",
    "    ## inverse applicant frequency\n",
    "    iaf = np.log(num_applicants / len(neigh_app))\n",
    "    ## conmittee consensus rate\n",
    "    all_hit_applicant_committee = sum([\n",
    "        app_committee_count[app] for app in neigh_app\n",
    "    ])\n",
    "    mention_hit_applicant_committee = len(neigh_com)\n",
    "    \n",
    "    ccr = mention_hit_applicant_committee / all_hit_applicant_committee\n",
    "    iccr = (np.log(all_hit_applicant_committee / mention_hit_applicant_committee) + 1) ** -1\n",
    "    \n",
    "#     uniqueness = iaf * iccr\n",
    "    uniqueness = iaf * ccr\n",
    "    \n",
    "    split_comments_uniqueness.append(uniqueness)\n",
    "    split_comments_iaf.append(iaf)\n",
    "    split_comments_iccr.append(iccr)\n",
    "    split_comments_ccr.append(ccr)\n",
    "    \n",
    "    split_comments_iaf_dict[sc] = iaf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c498ef2",
   "metadata": {},
   "source": [
    "### Plot uniqueness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e7f774",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4, 1, figsize=(5, 10), constrained_layout=True)\n",
    "\n",
    "## Uniqueness\n",
    "_ = axs[0].plot(np.sort(split_comments_uniqueness)[::-1])\n",
    "_ = axs[0].set_title(\"Sorted uniqueness\")\n",
    "\n",
    "## iaf\n",
    "_ = axs[1].plot(np.sort(split_comments_iaf)[::-1])\n",
    "_ = axs[1].set_title(\"Sorted inverse applicant frequency\")\n",
    "\n",
    "## iccr\n",
    "_ = axs[2].plot(np.sort(split_comments_iccr)[::-1])\n",
    "_ = axs[2].set_title(\"Sorted inverse comittee concensus rate\")\n",
    "\n",
    "## icr\n",
    "_ = axs[3].plot(np.sort(split_comments_ccr)[::-1])\n",
    "_ = axs[3].set_title(\"Sorted comittee concensus rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1c873c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, idx in enumerate(np.argsort(split_comments_uniqueness)[::-1]):\n",
    "#     if split_comments_iaf[idx] > 7:\n",
    "#         continue\n",
    "    \n",
    "    print(\n",
    "        \"{} {}, uniqueness: {:.3f}, iaf: {:.3f}, iccr, {:.3f}, ccr: {:.3f}\".format(\n",
    "        i, \n",
    "        split_comments[idx], \n",
    "        split_comments_uniqueness[idx], \n",
    "        split_comments_iaf[idx], \n",
    "        split_comments_iccr[idx],\n",
    "        split_comments_ccr[idx],\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd80636",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, idx in enumerate(np.argsort(split_comments_iaf)[::-1]):\n",
    "    print(\n",
    "        \"{} {}, uniqueness: {:.3f}, iaf: {:.3f}, cr: {:.3f}\".format(\n",
    "        i, \n",
    "        split_comments[idx], \n",
    "        split_comments_uniqueness[idx], \n",
    "        split_comments_iaf[idx], \n",
    "        split_comments_ccr[idx]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7773645c",
   "metadata": {},
   "source": [
    "## Filter comment by inverse applicant frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3c15d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "iaf_threshold = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4a43c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "iaf_filtered_comment_dict = defaultdict(list)\n",
    "iaf_sc_cnt = 0\n",
    "\n",
    "for _, row in df_split_comments.iterrows():\n",
    "    sc = row['split_comment']\n",
    "\n",
    "    ## get iaf value\n",
    "    iaf = split_comments_iaf_dict[sc]\n",
    "    if iaf < iaf_threshold:\n",
    "        continue\n",
    "\n",
    "    iaf_sc_cnt += 1\n",
    "        \n",
    "    original_comment = row['original_comment']\n",
    "    for oc in original_comment:\n",
    "        committee = oc[0]\n",
    "        iaf_filtered_comment_dict[committee].append(sc)\n",
    "        \n",
    "iaf_sc_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f75d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(iaf_filtered_comment_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc572f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "iaf_filtered_comment = []\n",
    "\n",
    "for _, row in df_comments.iterrows():\n",
    "    _year = row['year']\n",
    "    _id = row['id']\n",
    "    _committee_number = row['committee_number']\n",
    "    \n",
    "    query = (_year, _id, _committee_number)\n",
    "    iaf_f_comment = \"，\".join(iaf_filtered_comment_dict[query])\n",
    "    if len(iaf_f_comment) > 0:\n",
    "        iaf_f_comment += \"。\"\n",
    "        print(iaf_f_comment)\n",
    "        \n",
    "    iaf_filtered_comment.append(iaf_f_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515fad92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_comments['iaf_filtered_comment'] = iaf_filtered_comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4667da51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96c2be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.write_df_comments(df_comments, file='csv')\n",
    "D.write_df_comments(df_comments, file='pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7b7df3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research_venv",
   "language": "python",
   "name": "research_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
