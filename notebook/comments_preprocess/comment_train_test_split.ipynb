{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "from importlib import reload\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress: \")\n",
    "\n",
    "# Utility variable\n",
    "import sys\n",
    "sys.path.insert(0, '../..')\n",
    "\n",
    "# var\n",
    "import var.var as V\n",
    "\n",
    "# utils\n",
    "import utils.data as D\n",
    "import utils.io as IO\n",
    "import utils.preprocess as PP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_applicants = D.read_df_applicants()\n",
    "df_applicants.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments = D.read_df_comments()\n",
    "split_comments = D.read_split_comments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_comments = D.read_split_comments()\n",
    "split_comments_nsp = D.read_split_comments_nsp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find train/test idx for `split_comments`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_sc_idx = []\n",
    "test_sc_idx = []\n",
    "\n",
    "ref = df_comments.split_comment.to_list()\n",
    "\n",
    "i = 0\n",
    "j = 0\n",
    "\n",
    "for sc_idx, _sc in tqdm(enumerate(split_comments)):\n",
    "    found_sc = False\n",
    "    \n",
    "    while not found_sc:\n",
    "        ## empty comment\n",
    "        if len(ref[i]) == 0:\n",
    "            i += 1\n",
    "            continue\n",
    "            \n",
    "        ## already iterate through one comment\n",
    "        if j >= len(ref[i]):\n",
    "            i += 1\n",
    "            j = 0\n",
    "            continue\n",
    "        \n",
    "        if _sc == ref[i][j]:\n",
    "            _year = df_comments.iloc[i]['year']\n",
    "            _id = df_comments.iloc[i]['id']\n",
    "            \n",
    "            train_or_test = df_applicants.query(\n",
    "                '`year` == {} and `id` == {}'.format(_year, _id)\n",
    "            )['train_or_test'].to_list()[0]\n",
    "            \n",
    "            if train_or_test == 'train':\n",
    "                train_sc_idx.append(sc_idx)\n",
    "                found_sc = True\n",
    "            elif train_or_test == 'test':\n",
    "                test_sc_idx.append(sc_idx)\n",
    "                found_sc = True\n",
    "                \n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_train_test_list = [0] * len(split_comments)\n",
    "\n",
    "for i in train_sc_idx:\n",
    "    sc_train_test_list[i] = 'train'\n",
    "\n",
    "for i in test_sc_idx:\n",
    "    sc_train_test_list[i] = 'test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find train/test idx for `split_comment_nsp`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_sc_nsp_idx = []\n",
    "test_sc_nsp_idx = []\n",
    "\n",
    "ref = df_comments.split_comment_nsp.to_list()\n",
    "\n",
    "i = 0\n",
    "j = 0\n",
    "\n",
    "for sc_nsp_idx, _sc_nsp in tqdm(enumerate(split_comments_nsp)):\n",
    "    found_sc_nsp = False\n",
    "\n",
    "    while not found_sc_nsp:\n",
    "        ## empty comment\n",
    "        if len(ref[i]) == 0:\n",
    "            i += 1\n",
    "            continue\n",
    "            \n",
    "        ## already iterate through one comment\n",
    "        if j >= len(ref[i]):\n",
    "            i += 1\n",
    "            j = 0\n",
    "            continue\n",
    "        \n",
    "        if _sc_nsp == ref[i][j]:\n",
    "            _year = df_comments.iloc[i]['year']\n",
    "            _id = df_comments.iloc[i]['id']\n",
    "            \n",
    "            train_or_test = df_applicants.query(\n",
    "                '`year` == {} and `id` == {}'.format(_year, _id)\n",
    "            )['train_or_test'].to_list()[0]\n",
    "            \n",
    "            if train_or_test == 'train':\n",
    "                train_sc_nsp_idx.append(sc_nsp_idx)\n",
    "                found_sc_nsp = True\n",
    "            elif train_or_test == 'test':\n",
    "                test_sc_nsp_idx.append(sc_nsp_idx)\n",
    "                found_sc_nsp = True\n",
    "                \n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_nsp_train_test_list = [0] * len(split_comments_nsp)\n",
    "\n",
    "for i in train_sc_nsp_idx:\n",
    "    sc_nsp_train_test_list[i] = 'train'\n",
    "\n",
    "for i in test_sc_nsp_idx:\n",
    "    sc_nsp_train_test_list[i] = 'test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find train/test idx for `split_comments_no_duplicate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_comments_no_duplicate = []\n",
    "\n",
    "train_sc_nd_idx = []\n",
    "test_sc_nd_idx = []\n",
    "sc_nd_train_test_list = []\n",
    "\n",
    "for sc, train_or_test in zip(split_comments, sc_train_test_list):\n",
    "    if sc not in split_comments_no_duplicate:\n",
    "        idx = len(split_comments_no_duplicate)\n",
    "        \n",
    "        if train_or_test == 'train':\n",
    "            train_sc_nd_idx.append(idx)\n",
    "            sc_nd_train_test_list.append('train')\n",
    "        elif train_or_test == 'test':\n",
    "            test_sc_nd_idx.append(idx)\n",
    "            sc_nd_train_test_list.append('test')\n",
    "        \n",
    "        split_comments_no_duplicate.append(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find train/test idx for `split_comments_nsp_no_duplicate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_comments_nsp_no_duplicate = []\n",
    "\n",
    "train_sc_nsp_nd_idx = []\n",
    "test_sc_nsp_nd_idx = []\n",
    "sc_nsp_nd_train_test_list = []\n",
    "\n",
    "for sc_nsp, train_or_test in zip(split_comments_nsp, sc_nsp_train_test_list):\n",
    "    if sc_nsp not in split_comments_nsp_no_duplicate:\n",
    "        idx = len(split_comments_nsp_no_duplicate)\n",
    "        \n",
    "        if train_or_test == 'train':\n",
    "            train_sc_nsp_nd_idx.append(idx)\n",
    "            sc_nsp_nd_train_test_list.append('train')\n",
    "        elif train_or_test == 'test':\n",
    "            test_sc_nsp_nd_idx.append(idx)\n",
    "            sc_nsp_nd_train_test_list.append('test')\n",
    "        \n",
    "        split_comments_nsp_no_duplicate.append(sc_nsp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_comments_train_test_indices = {\n",
    "    \"split_comments\": {\n",
    "        \"train_idx\": train_sc_idx,\n",
    "        \"test_idx\": test_sc_idx,\n",
    "        \"train_test_list\": sc_train_test_list,\n",
    "    },\n",
    "    \"split_comments_no_duplicate\": {\n",
    "        \"train_idx\": train_sc_nd_idx,\n",
    "        \"test_idx\": test_sc_nd_idx,\n",
    "        \"train_test_list\": sc_nd_train_test_list,\n",
    "    },\n",
    "    \"split_comments_nsp\": {\n",
    "        \"train_idx\": train_sc_nsp_idx,\n",
    "        \"test_idx\": test_sc_nsp_idx,\n",
    "        \"train_test_list\": sc_nsp_train_test_list,\n",
    "    },\n",
    "    \"split_comments_nsp_no_duplicate\": {\n",
    "        \"train_idx\": train_sc_nsp_nd_idx,\n",
    "        \"test_idx\": test_sc_nsp_nd_idx,\n",
    "        \"train_test_list\": sc_nsp_nd_train_test_list,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write split comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D.write_split_comments_no_duplicate(split_comments_no_duplicate)\n",
    "D.write_split_comments_nsp_no_duplicate(split_comments_nsp_no_duplicate)\n",
    "D.write_split_comments_train_test_indices(split_comments_train_test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research_venv",
   "language": "python",
   "name": "research_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
